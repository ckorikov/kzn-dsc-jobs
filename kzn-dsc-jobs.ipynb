{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "import Stemmer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954\n",
      "954\n"
     ]
    }
   ],
   "source": [
    "f = open('kzn-dsc/dataset.json')\n",
    "jobs = json.load(f)\n",
    "print(len(jobs))\n",
    "jobs = [job for job in jobs if job['text'] != 'This message was deleted.']\n",
    "print(len(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = defaultdict(int)\n",
    "\n",
    "for job in jobs:\n",
    "    for reaction in job['reactions']:\n",
    "        # print(reaction)\n",
    "        counter[reaction] += job['reactions'][reaction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_reactions = sorted(counter.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ico', 226),\n",
       " ('grammar', 234),\n",
       " ('venheads', 238),\n",
       " ('money_mouth_face', 249),\n",
       " ('heavy_plus_sign', 249),\n",
       " ('tinkoff', 269),\n",
       " ('rowing-galera', 279),\n",
       " ('+1::skin-tone-6', 308),\n",
       " ('nor', 340),\n",
       " ('mickey', 347),\n",
       " ('ramen', 374),\n",
       " ('hankey', 377),\n",
       " ('wat', 391),\n",
       " ('chains', 403),\n",
       " ('joy', 408),\n",
       " ('noexcel', 426),\n",
       " ('putin', 430),\n",
       " ('moneys', 442),\n",
       " ('facepalm', 553),\n",
       " ('+1::skin-tone-2', 622),\n",
       " ('moneybag', 663),\n",
       " ('sberbank', 770),\n",
       " ('eww', 881),\n",
       " ('fireball', 917),\n",
       " ('notbad', 1694),\n",
       " ('fire', 2089),\n",
       " ('galera', 3727),\n",
       " ('+1', 5590),\n",
       " ('ban', 6281),\n",
       " ('fork', 7084)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_reactions[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_reactions = ['+1', 'fire', 'notbad', 'fireball', 'moneybag', 'heavy_plus_sign', 'money_mouth_face', '+1::skin-tone-2']\n",
    "bad_reactions = ['ban', 'fork', 'galera', 'eww', 'facepalm', 'wat', 'rowing-galera', 'are_you_fucking_kidding_me', 'noexcel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_good_reactions = sum([counter[reaction] for reaction in good_reactions])\n",
    "amount_of_bad_reactions = sum([counter[reaction] for reaction in bad_reactions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12073\n",
      "19831\n"
     ]
    }
   ],
   "source": [
    "print(amount_of_good_reactions)\n",
    "print(amount_of_bad_reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = Stemmer.Stemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer, RussianStemmer\n",
    "\n",
    "ru_stemmer = RussianStemmer()\n",
    "eng_stemmer = EnglishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def perfotm_transformation(text):\n",
    "    text = text.lower()\n",
    "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    text = text.translate(translator)\n",
    "    words_without_punctuation = text.split()\n",
    "    # 3. Stem words\n",
    "    stemmed_words = [eng_stemmer.stem(ru_stemmer.stem(word)) for word in words_without_punctuation]\n",
    "    \n",
    "    return ' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Привет! Мы в Dbrain (<https://dbrain.io>) снова (вот в прошлый раз: <https://opendatascience.slack.com/archives/C04DA5FUF/p1519145569000376>) ищем дата-саентистов, на этот раз нам нужно два человека: - синьор - джуниор плюс (знает основы, уверенно идет к миддлу) Требования: - Опыт работы с современным DL фреймворкам (pytorch, tf, keras, mxnet). Мы в основном предпочитаем pytorch, но это не принципиально; - Опыт работы с python (scipy stack); - Опыт работы с дженерик моделями sklearn, xgboost, etc; - Опыт работы в ОС Linux (GNU tools, bash); - Опыт запуска моделей в лайт прод, показ MVP. Будет плюсом:: - Знает SQL; - Знание C/C++. При наличии убедительных аргументов полная свобода в принятии ключевых решений в выборе подходов / алгоритмов / фреймворков. Ну и мы всегда готовы советовать и помогать со своей стороны. Перспективы: - Стать лидом отдельной команды, разрабатывающей конкретный проект; - Возможность реализовать свою амбициозную идею. Условия: - Красивый офис между Новокузнецкой и Павелецкой; - На кухне есть печенье, чай, кофемашина и все необходимое для сборки бутерброда; - Оформление по ТК; - Джуниору до 120к, синьору до 250к на руки. Резюме лучше всего присылать на <mailto:job@dbrain.io|job@dbrain.io> (в теме лучше всего указать свое имя и желаемую позицию), если будете писать в треде - могу что-то пропустить.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[4]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'привет мы в dbrain https dbrain i снов вот в прошл раз https opendatascienc slack com archiv c04da5fuf p1519145569000376 ищ дат саентист на этот раз нам нужн два человек синьор джуниор плюс знает основ уверен идет к миддл требован оп работ с современ dl фреймворк pytorch tf kera mxnet мы в основн предпочита pytorch но эт не принципиальн оп работ с python scip stack оп работ с дженерик модел sklearn xgboost etc оп работ в ос linux gnu tool bash оп запуск модел в лайт прод показ mvp будет плюс знает sql знан c c при налич убедительн аргумент полн свобод в принят ключев решен в выбор подход алгоритм фреймворк ну и мы всегд готов советова и помога со сво сторон перспектив стат лид отдельн команд разрабатыва конкретн проект возможн реализова сво амбициозн ид услов красив офис межд новокузнецк и павелецк на кухн ест печен ча кофемашин и все необходим для сборк бутерброд оформлен по тк джуниор до 120к синьор до 250к на рук резюм лучш всег присыла на mailt job dbrain i job dbrain i в тем лучш всег указа сво им и жела позиц есл будет писа в тред мог что то пропуст'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfotm_transformation(jobs[4]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_texts = [perfotm_transformation(job['text']) for job in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_job_galera(job):\n",
    "    positive_reactions = sum([job['reactions'][reaction] for reaction in job['reactions'] if reaction in good_reactions])\n",
    "    negative_reactions = sum([job['reactions'][reaction] for reaction in job['reactions'] if reaction in bad_reactions])\n",
    "    return negative_reactions > positive_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = []\n",
    "for job in jobs:\n",
    "    if is_job_galera(job):\n",
    "        y_labels.append(1)\n",
    "    else:\n",
    "        y_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "X = vectorizer.fit_transform(transformed_texts)\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<954x14421 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 133577 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=19, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(C=1, random_state=19)\n",
    "logit.fit(X_tfidf, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8825995807127882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = logit.predict(X_tfidf)\n",
    "print(accuracy_score(predictions, y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer_word = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1, 5))\n",
    "train_word = vectorizer_word.fit_transform(transformed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=19, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(C=1, random_state=19)\n",
    "logit.fit(train_word, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9769392033542977\n"
     ]
    }
   ],
   "source": [
    "predictions = logit.predict(train_word)\n",
    "print(accuracy_score(predictions, y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=15)\n",
    "clf = clf.fit(train_word, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8522012578616353\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(train_word)\n",
    "print(accuracy_score(predictions, y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(clf, out_file='small_tree_1.dot', filled=True, feature_names=vectorizer_word.get_feature_names())\n",
    "# для этого понадобится библиотека pydot (pip install pydot)\n",
    "!dot -Tpng 'small_tree.dot' -o 'small_tree_1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Требуется Senior Data scientist в международную компанию. OSA Hybrid Platform – сервис на основе BIG DATA платформы, управляемый прикладным Искусственным Интеллектом, повышающий уровень наличия товара на полке. Сервис работает в режиме реального времени. В проекте участвуют торговые сети, входящие в ТОП 10 ритейлеров: Перекресток, Dixy, Auchan, METRO Cash &amp; Carry, АВ Daily и пр. Так же, задействованы крупнейшие компании производители, среди них: Pepsi, Coca-Cola, Danone, JTI, Mars, Loreal, SanInBev, Efes, Unilever, Эфко и пр. Обязанности: • Менторство DS команды проекта. • Расширение круга гипотез в процессе анализа поведения потребителей в офф-лайн ритейле (фуд). • Расширение круга факторов, доступных для анализа (meta data, open data). • Проектирование и реализация алгоритмов прогноза покупательского поведения основанные на больших данных, используя машинное обучение. • Дата инжиниринг. • Покупательская сегментация и целевой маркетинг. • Курирование работы по созданию Каталогов мастер данных, магазинов и покупателей (очистка, обогащение, присвоение атрибутов). Стек используемых технологий: • Python. • Machine learning. • Neural networks. • Deep learning. • Numpy. • xGboost. • Sklearn. • PostgreSQL. • ClickHouse. Офис: Москва м. Беговая, либо Киев мкр-н Воздвиженка. Мы предлагаем: • Достойную, справедливую зарплату по результатам собеседований. • Корпоративный оплачиваемый английский язык. • Посещение тематических конференций. • Работу по Аgile в самоуправляемой команде. • Гибкий график работы. • Мы предлагаем опыт работы разработки уникального продукта с применением искусственного интеллекта в сфере Ритейла и FMCG. Направляйте резюме на адрес: <mailto:y.kartashova@osahp.com|y.kartashova@osahp.com>', 'reactions': {'fork': 36, 'grammar': 9, 'ballpok': 1, 'pikachu_dancing': 3, 'ban': 20, 'baby_rage': 2, 'xgboost': 1}}\n",
      "1\n",
      "треб senior dat scientist в международн компан os hybrid platform – сервис на основ big dat платформ управля прикладн искусствен интеллект повыша уровен налич товар на полк сервис работа в режим реальн времен в проект участв торгов сет входя в топ 10 ритейлер перекресток dix aucha metr cash amp carr ав dail и пр так же задействова крупн компан производител сред них pep coc col danon jti mar lorea saninb efe unilev эфк и пр обязан • менторств ds команд проект • расширен круг гипотез в процесс анализ поведен потребител в офф лайн ритейл фуд • расширен круг фактор доступн для анализ met dat op dat • проектирован и реализац алгоритм прогноз покупательск поведен основа на больш дан использу машин обучен • дат инжиниринг • покупательск сегментац и целев маркетинг • курирован работ по создан каталог мастер дан магазин и покупател очистк обогащен присвоен атрибут стек используем технолог • python • machin learn • neura network • deep learn • nump • xgboost • sklearn • postgresql • clickhous офис москв м бегов либ ки мкр н воздвиженк мы предлага • достойн справедлив зарплат по результат собеседован • корпоративн оплачива английск язык • посещен тематическ конференц • работ по агил в самоуправля команд • гибк график работ • мы предлага оп работ разработк уникальн продукт с применен искусствен интеллект в сфер ритейл и fmcg направля резюм на адрес mailt y kartashov osahp com y kartashov osahp com\n"
     ]
    }
   ],
   "source": [
    "job_index = 850\n",
    "print(jobs[job_index])\n",
    "print(y_labels[job_index])\n",
    "print(transformed_texts[job_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9282178217821783\n",
      "0.7700205338809035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(predictions, y_labels))\n",
    "print(recall_score(predictions, y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(model, X, y):\n",
    "    model.fit(X, y)\n",
    "    predictions = model.predict(X)\n",
    "    print(\"---------Training--------\")\n",
    "    print(\"Accuracy score: \" + str(accuracy_score(y, np.where(predictions > 0.5, 1, 0))))\n",
    "    print(\"Precision score: \" + str(precision_score(y, np.where(predictions > 0.5, 1, 0))))\n",
    "    print(\"Recall score: \" + str(recall_score(y, np.where(predictions > 0.5, 1, 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Training--------\n",
      "Accuracy score: 0.7987421383647799\n",
      "Precision score: 0.6840277777777778\n",
      "Recall score: 0.9752475247524752\n"
     ]
    }
   ],
   "source": [
    "fit_predict(clf, X_tfidf, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6331236897274634"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(clf.predict(X_tfidf), y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Training--------\n",
      "Accuracy score: 0.9748427672955975\n",
      "Precision score: 1.0\n",
      "Recall score: 0.9392405063291139\n"
     ]
    }
   ],
   "source": [
    "fit_predict(logit, train_word, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def run_cv(model, X, y, test):\n",
    "    n_folds = 10\n",
    "    #skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "    skf = KFold(n_splits=10, random_state=0)\n",
    "    data_x = X\n",
    "    data_y = y\n",
    "    pred = []\n",
    "    for train_index, test_index in skf.split(data_x, data_y):\n",
    "        x_train, x_test = np.array(data_x)[train_index], np.array(data_x)[test_index]\n",
    "        y_train, y_test = np.array(data_y)[train_index], np.array(data_y)[test_index]\n",
    "        \n",
    "        tfidf = TfidfVectorizer(sublinear_tf=True, analyzer='word', stop_words='english', ngram_range=(1, 1))\n",
    "        #tfidf = vectorizer_word\n",
    "        tfidf.fit(X)\n",
    "        \n",
    "        x_train = tfidf.transform(x_train)\n",
    "        x_test = tfidf.transform(x_test)\n",
    "        test_tfidf = tfidf.transform(test)\n",
    "        \n",
    "#         char_vectorizer = TfidfVectorizer(\n",
    "#                             sublinear_tf=True,\n",
    "#                             analyzer='char',\n",
    "#                             stop_words='english',\n",
    "#                             ngram_range=(2, 6),\n",
    "#                             max_features=50000)\n",
    "#         char_vectorizer.fit(X)\n",
    "        \n",
    "#         train_char_features = char_vectorizer.transform(x_train)\n",
    "#         test_char_features = char_vectorizer.transform(x_test)\n",
    "#         tfidf = vectorizer_word\n",
    "#         x_train = tfidf.transform(x_train)\n",
    "#         x_test = tfidf.transform(x_test)\n",
    "#         x_train = hstack([train_char_features, x_train])\n",
    "#         x_test = hstack([test_char_features, x_test])\n",
    "        fit_predict(model, x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        # score = accuracy_score(y_test, y_pred)\n",
    "        prediction = model.predict(test_tfidf)\n",
    "        pred.append(prediction[:])\n",
    "        print(sum(y_pred))\n",
    "        print(\"---------Validation------\")\n",
    "        print(\"Accuracy score: \" + str(accuracy_score(y_test, np.where(y_pred > 0.5, 1, 0))))\n",
    "        print(\"Precision score: \" + str(precision_score(y_test, np.where(y_pred > 0.5, 1, 0))))\n",
    "        print(\"Recall score: \" + str(recall_score(y_test, np.where(y_pred > 0.5, 1, 0))))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "gbm = lgb.LGBMRegressor(num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Training--------\n",
      "Accuracy score: 0.9468911917098446\n",
      "Precision score: 0.9866666666666667\n",
      "Recall score: 0.8888888888888888\n",
      "38.282050209927675\n",
      "---------Validation------\n",
      "Accuracy score: 0.5813953488372093\n",
      "Precision score: 0.4230769230769231\n",
      "Recall score: 0.34375\n",
      "---------Training--------\n",
      "Accuracy score: 0.9378238341968912\n",
      "Precision score: 0.9859649122807017\n",
      "Recall score: 0.8646153846153846\n",
      "36.39188700204581\n",
      "---------Validation------\n",
      "Accuracy score: 0.6511627906976745\n",
      "Precision score: 0.8125\n",
      "Recall score: 0.325\n",
      "---------Training--------\n",
      "Accuracy score: 0.9417098445595855\n",
      "Precision score: 0.9801324503311258\n",
      "Recall score: 0.8835820895522388\n",
      "36.54795880153649\n",
      "---------Validation------\n",
      "Accuracy score: 0.6162790697674418\n",
      "Precision score: 0.43478260869565216\n",
      "Recall score: 0.3333333333333333\n",
      "---------Training--------\n",
      "Accuracy score: 0.939119170984456\n",
      "Precision score: 0.9795918367346939\n",
      "Recall score: 0.8753799392097265\n",
      "36.001727106495345\n",
      "---------Validation------\n",
      "Accuracy score: 0.5813953488372093\n",
      "Precision score: 0.5\n",
      "Recall score: 0.2777777777777778\n",
      "---------Training--------\n",
      "Accuracy score: 0.9339378238341969\n",
      "Precision score: 0.9892857142857143\n",
      "Recall score: 0.8523076923076923\n",
      "34.873231419111555\n",
      "---------Validation------\n",
      "Accuracy score: 0.5465116279069767\n",
      "Precision score: 0.5333333333333333\n",
      "Recall score: 0.2\n",
      "---------Training--------\n",
      "Accuracy score: 0.9546632124352331\n",
      "Precision score: 0.9966216216216216\n",
      "Recall score: 0.8966565349544073\n",
      "37.72560988563297\n",
      "---------Validation------\n",
      "Accuracy score: 0.5697674418604651\n",
      "Precision score: 0.47619047619047616\n",
      "Recall score: 0.2777777777777778\n",
      "---------Training--------\n",
      "Accuracy score: 0.939119170984456\n",
      "Precision score: 0.9863013698630136\n",
      "Recall score: 0.8700906344410876\n",
      "37.88076320874822\n",
      "---------Validation------\n",
      "Accuracy score: 0.5930232558139535\n",
      "Precision score: 0.48\n",
      "Recall score: 0.35294117647058826\n",
      "---------Training--------\n",
      "Accuracy score: 0.9404145077720207\n",
      "Precision score: 0.9827586206896551\n",
      "Recall score: 0.8742331288343558\n",
      "35.365254597750074\n",
      "---------Validation------\n",
      "Accuracy score: 0.5581395348837209\n",
      "Precision score: 0.5454545454545454\n",
      "Recall score: 0.15384615384615385\n",
      "---------Training--------\n",
      "Accuracy score: 0.944372574385511\n",
      "Precision score: 0.9832214765100671\n",
      "Recall score: 0.8851963746223565\n",
      "35.39957857933317\n",
      "---------Validation------\n",
      "Accuracy score: 0.5176470588235295\n",
      "Precision score: 0.3157894736842105\n",
      "Recall score: 0.17647058823529413\n",
      "---------Training--------\n",
      "Accuracy score: 0.9353169469598965\n",
      "Precision score: 0.9963369963369964\n",
      "Recall score: 0.8473520249221184\n",
      "34.52894753356544\n",
      "---------Validation------\n",
      "Accuracy score: 0.5647058823529412\n",
      "Precision score: 0.7058823529411765\n",
      "Recall score: 0.2727272727272727\n",
      "---------Hold-out---------\n",
      "Accuracy score: 0.625\n",
      "Precision score: 0.6666666666666666\n",
      "Recall score: 0.15384615384615385\n"
     ]
    }
   ],
   "source": [
    "y_pred = run_cv(gbm, train, y_train, test)\n",
    "\n",
    "y_pred = np.mean(y_pred, axis = 0)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "print(\"---------Hold-out---------\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0,  0,  0,  1,  0,  0,  1,\n",
       "        0,  0,  0,  0,  1,  0,  0,  1, -1,  0,  1,  0,  0, -1,  1,  1,  1,\n",
       "        1,  0,  0,  1,  0,  1,  1,  1,  0,  1,  1,  0,  0,  1,  0,  0,  0,\n",
       "        0,  1,  0,  1,  1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  0,\n",
       "        1,  0,  0,  1,  0,  0,  0,  1,  1, -1,  0])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
